package ec.pta;

import ec.util.*;
import ec.*;
import ec.app.regression.Benchmarks;
import ec.app.regression.RegressionData;
import ec.gp.*;
import ec.gp.koza.*;
import ec.simple.*;

import java.io.*;
import java.util.*;

/* 
 * Benchmarks.java
 * U    
 * Created: Thu Jul 14 10:35:11 EDT 2011
 * By: Sean Luke
 *
 * This is an expansion of the Regression.java file to provide a first cut at a standardized
 * regression benchmark for Genetic Programming.  The package provides both training and
 * testing data and functions for the following problems:
 
 <ol>
 <li>John Koza's three  problems (quartic, quintic, and sextic, drawn from his GP-1 and GP-2 books.  These are known as <b>koza-1</b> through <b>koza-3</b>
 <li>Twelve problems drawn from "Semantically-based Crossover in Genetic Programming: Application to Real-valued Symbolic Regression" (GPEM 2011),
 by Nguyen Quang Uy, Nguyen Xuan Hoai, Michael O’Neill, R.I. McKay, Edgar Galv ́an-L ́opez.  These are known as
 <b>nguyen-1</b> through <b>nguyen-10</b>
 <li>Fifteen problems drawn from "Accuracy in Symbolic Regression" (GPEM 2011), by Michael Korns.  These are known as <b>KORNS1</b> through <b>KORNS15</b>
 <li>Fifteen problems drawn from "Improving Symbolic Regression with Interval Arithmetic and Linear Scaling" (EuroGP 2003), by Maarten Keijzer.  These are known as <b>keijzer-1</b> through <b>keijzer-15</b>
 <li>Fifteen problems drawn from "Order of Nonlinearity as a Complexity Measure for Models Generated by Symbolic Regression via Pareto Genetic Programming" (IEEE TransEC 13:2), by Ekaterina J. Vladislavleva, Guido F. Smits, and Dick den Hertog.  These are known as <b>vladislavleva-1</b> through <b>vladislavleva-8</b>
 <li>Two problems drawn from "Evolutionary Consequences of Coevolving Targets" (Evolutionary Computation 5(4)) by Ludo Pagie and Paulien Hogeweg, 1997.
 <li>You can also provide your own data sets via a text file.

 <p>These problems differ in a variety of ways.  Some have both training and testing data points.  Some have one variable, others up to five variables.  Some build their random points based on random samples, other based on a grid of samples distributed through the space.  Different problems also use different function sets.
 
 <p>The functions below are all described precisely in the paper "Genetic Programming Needs Better Benchmarks" (GECCO 2012) by James McDermmott, David R. white, Sean Luke, Luca Manzoni, Mauro Castelli, Leonardo Vanneschi, Wojciech Jaskowski, Krzysztof Krawiec, Robin Harper, Kenneth De Jong, and Una-May O'Reilly.  The descriptions, shown in Tables 2 and 3, explain the function set, number of variables, objective function, training set, testing set, and source of each problem.
 
 <p>In addition we include one more function: PAGIE2, a 3-variable version of PAGIE1. We describe PAGIE2 as follows:
 
 <ul>
 <li>Variables: 3
 li>Function: (1 / (1 + x^(-4)) + 1 / (1 + y^(-4)) + 1 / (1 + z^(-4)))
 <li>Testing Set: Grid points from -5 to 5 respectively in each dimension, spaced out in intervals of 0.4.
 <li>Training Set: none
 <li>Function Set: standard Koza with three terminals (X1, X2, X3).
 </ul>

 *
 *
 */

/**
 * Benchmarks by various people in the literature.
 *  
 *  
 *  Bias Variance Problem
 */
public class BVProblem extends Benchmarks
    {
	
	/**
     * Stochastic Fitness
     */
    public final int MAXBOOTSAMPLE = 1500;
	public final int NUMBOOTSAMPLE = 50; //B
	public int[][] dataSet;// = new int[MAXBOOTSAMPLE][trainingInputs.length];
	
	private void bootstrapSampling()
	{	
		dataSet = new int[MAXBOOTSAMPLE][trainingInputs.length];

		Random rand = new Random(1000);
		
		for(int i = 0; i < MAXBOOTSAMPLE; i++)
		{
			for (int j = 0; j < trainingInputs.length; j++)
				dataSet[i][j] = rand.nextInt(trainingInputs.length);
		}
	}
	
	

	
	public void setup(EvolutionState state, Parameter base)
	{
		super.setup(state, base);
		
		bootstrapSampling();
	}
///// Evaluation.  evaluate(...) uses training cases, and describe(...) uses testing cases


    public void evaluate(EvolutionState state, Individual ind, int subpopulation, int threadnum)
    {
        if (!ind.evaluated)  // don't bother reevaluating
        {
            RegressionData input = (RegressionData)(this.input);

            int hits = 0;
            double mean = 0;
            double[] errors = new double[trainingInputs.length];
            
            for (int y=0;y<trainingInputs.length;y++)
            {
            	double error = 0;
            	
        		currentValue = trainingInputs[y];
        		((GPIndividual)ind).trees[0].child.eval(
        				state,threadnum,input,stack,((GPIndividual)ind),this);
            
        		//store semantic of y-th element
        		((GPIndividual)ind).trees[0].semanticTraining[y] = input.x;
                        	            		
        		errors[y] = error(input.x, trainingOutputs[y]);
            		   
        		mean += errors[y];
            }
            mean = mean/trainingInputs.length;
            
            double variance = 0;
            double[] bias = new double[NUMBOOTSAMPLE];
            double sum = 0;
            for (int i = 0; i < NUMBOOTSAMPLE; i++)
            {
            	int index = state.random[0].nextInt(MAXBOOTSAMPLE);
            	bias[i] = 0;
            	for(int j = 0; j < trainingInputs.length; j++)
            	{
            		bias[i] += errors[dataSet[index][j]];
            	}
            	sum += bias[i];
            }
            
            sum = sum/NUMBOOTSAMPLE;
            for(int i = 0; i < bias.length; i++)
            {
            	variance += Math.pow(bias[i] - sum, 2);
            }
            variance = variance / (NUMBOOTSAMPLE- 1);
            
            double fitness = 0.7 * mean + 0.3 * variance;
            
            // the fitness better be KozaFitness!
            KozaFitness f = ((KozaFitness)ind.fitness);
            f.setStandardizedFitness(state,(float)fitness);
            f.hits = hits;
            
            ind.evaluated = true;
            
            
        }
        
        
        
    }


    public void describe(EvolutionState state, Individual ind, int subpopulation, int threadnum, int log)
    {
        RegressionData input = (RegressionData)(this.input);

        // we do the testing set here
        
        //state.output.println("\n\nPerformance of Best Individual on Testing Set:\n", log);
        
        //((GPIndividual)ind).trees[0].printTreeForHumans(state, log);
        
        int hits = 0;
        double sum = 0.0;
        for (int y=0;y<testingInputs.length;y++)
        {
        	double error = 0;
        	
    		currentValue = testingInputs[y];
    		((GPIndividual)ind).trees[0].child.eval(
    				state,threadnum,input,stack,((GPIndividual)ind),this);

    		error = error(input.x, testingOutputs[y]);
        	
            // We'll keep the auxillary hits measure for tradition only 
            final double HIT_LEVEL = 0.01;
            if (error <= HIT_LEVEL) hits++; 

            sum += error;
            
        }
        // the fitness better be KozaFitness!
        KozaFitness f = (KozaFitness)(ind.fitness.clone());     // make a copy, we're just printing it out
        f.setStandardizedFitness(state,(float)sum/testingInputs.length);
        f.hits = hits;
        state.output.print("" + f.standardizedFitness() + " ", log);     


    }

        
    }
