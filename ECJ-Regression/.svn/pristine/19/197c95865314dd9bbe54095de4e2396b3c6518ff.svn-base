package ec.app.regression;
import ec.util.*;
import ec.*;
import ec.gp.*;
import ec.gp.koza.*;
import ec.simple.*;
import java.io.*;
import java.util.*;

/* 
 * Benchmarks.java
 * U    
 * Created: Thu Jul 14 10:35:11 EDT 2011
 * By: Sean Luke
 *
 * This is an expansion of the Regression.java file to provide a first cut at a standardized
 * regression benchmark for Genetic Programming.  The package provides both training and
 * testing data and functions for the following problems:
 
 <ol>
 <li>John Koza's three  problems (quartic, quintic, and sextic, drawn from his GP-1 and GP-2 books.  These are known as <b>koza-1</b> through <b>koza-3</b>
 <li>Twelve problems drawn from "Semantically-based Crossover in Genetic Programming: Application to Real-valued Symbolic Regression" (GPEM 2011),
 by Nguyen Quang Uy, Nguyen Xuan Hoai, Michael O’Neill, R.I. McKay, Edgar Galv ́an-L ́opez.  These are known as
 <b>nguyen-1</b> through <b>nguyen-10</b>
 <li>Fifteen problems drawn from "Accuracy in Symbolic Regression" (GPEM 2011), by Michael Korns.  These are known as <b>KORNS1</b> through <b>KORNS15</b>
 <li>Fifteen problems drawn from "Improving Symbolic Regression with Interval Arithmetic and Linear Scaling" (EuroGP 2003), by Maarten Keijzer.  These are known as <b>keijzer-1</b> through <b>keijzer-15</b>
 <li>Fifteen problems drawn from "Order of Nonlinearity as a Complexity Measure for Models Generated by Symbolic Regression via Pareto Genetic Programming" (IEEE TransEC 13:2), by Ekaterina J. Vladislavleva, Guido F. Smits, and Dick den Hertog.  These are known as <b>vladislavleva-1</b> through <b>vladislavleva-8</b>
 <li>Two problems drawn from "Evolutionary Consequences of Coevolving Targets" (Evolutionary Computation 5(4)) by Ludo Pagie and Paulien Hogeweg, 1997.
 <li>You can also provide your own data sets via a text file.

 <p>These problems differ in a variety of ways.  Some have both training and testing data points.  Some have one variable, others up to five variables.  Some build their random points based on random samples, other based on a grid of samples distributed through the space.  Different problems also use different function sets.
 
 <p>The functions below are all described precisely in the paper "Genetic Programming Needs Better Benchmarks" (GECCO 2012) by James McDermmott, David R. white, Sean Luke, Luca Manzoni, Mauro Castelli, Leonardo Vanneschi, Wojciech Jaskowski, Krzysztof Krawiec, Robin Harper, Kenneth De Jong, and Una-May O'Reilly.  The descriptions, shown in Tables 2 and 3, explain the function set, number of variables, objective function, training set, testing set, and source of each problem.
 
 <p>In addition we include one more function: PAGIE2, a 3-variable version of PAGIE1. We describe PAGIE2 as follows:
 
 <ul>
 <li>Variables: 3
 li>Function: (1 / (1 + x^(-4)) + 1 / (1 + y^(-4)) + 1 / (1 + z^(-4)))
 <li>Testing Set: Grid points from -5 to 5 respectively in each dimension, spaced out in intervals of 0.4.
 <li>Training Set: none
 <li>Function Set: standard Koza with three terminals (X1, X2, X3).
 </ul>

 *
 *
 */

/**
 * Benchmarks by various people in the literature.
 *  
 *  
 *  GEOMETRIC SEMANTIC OF MORAGLIO
 */
public class Geometric extends Benchmarks
    {
	
	public void setup(EvolutionState state, Parameter base)
	{
		super.setup(state, base);
	}
///// Evaluation.  evaluate(...) uses training cases, and describe(...) uses testing cases


    public void evaluate(EvolutionState state, Individual ind, int subpopulation, int threadnum)
    {
        if (!ind.evaluated)  // don't bother reevaluating
        {
            RegressionData input = (RegressionData)(this.input);

            int hits = 0;
            double sum = 0.0;
            for (int y=0;y<trainingInputs.length;y++)
            {
            	double error = 0;
            	if(state.generation == 0)
            	{
            		currentValue = trainingInputs[y];
            		((GPIndividual)ind).trees[0].child.eval(
            				state,threadnum,input,stack,((GPIndividual)ind),this);
                
            		//store semantic of y-th element
            		((GPIndividual)ind).trees[0].semanticTraining[y] = input.x;
                            	            		
            		error = error(input.x, trainingOutputs[y]);
            		
            		
            	}   
            	else
            	{
            		double sm1 = ((GPIndividual)ind).trees[0].semanticTraining[y];
            		
            		error = error(sm1, trainingOutputs[y]);
            	}
                // We'll keep the auxillary hits measure for tradition only 
                final double HIT_LEVEL = 0.01;
                if (error <= HIT_LEVEL) hits++; 

                sum += error;              
            }
                
            // the fitness better be KozaFitness!
            KozaFitness f = ((KozaFitness)ind.fitness);
            f.setStandardizedFitness(state,(float)sum/trainingInputs.length);
            f.hits = hits;
            ind.evaluated = true;
            
            
        }
        
        // for testing
        if(state.generation == 0)
        {
            RegressionData input = (RegressionData)(this.input);
            for (int y=0;y<testingInputs.length;y++)
        	{
        		currentValue = testingInputs[y];
        		((GPIndividual)ind).trees[0].child.eval(
        				state,threadnum,input,stack,((GPIndividual)ind),this);
        		//store semantic of y-th element
        		((GPIndividual)ind).trees[0].semanticTesting[y] = input.x;

        	}
        }
        
    }


    public void describe(EvolutionState state, Individual ind, int subpopulation, int threadnum, int log)
    {
        RegressionData input = (RegressionData)(this.input);

        // we do the testing set here
        
        //state.output.println("\n\nPerformance of Best Individual on Testing Set:\n", log);
                
        int hits = 0;
        double sum = 0.0;
        for (int y=0;y<testingInputs.length;y++)
        {
        	double error = 0;
        	
    		error = error(((GPIndividual)ind).trees[0].semanticTesting[y],testingOutputs[y]);
        	
            // We'll keep the auxillary hits measure for tradition only 
            final double HIT_LEVEL = 0.01;
            if (error <= HIT_LEVEL) hits++; 

            sum += error;
            
        }
        // the fitness better be KozaFitness!
        KozaFitness f = (KozaFitness)(ind.fitness.clone());     // make a copy, we're just printing it out
        f.setStandardizedFitness(state,(float)sum/testingInputs.length);
        f.hits = hits;
        state.output.print("" + f.standardizedFitness() + " ", log);     

        //print tree
/*        if(state.generation == state.numGenerations-1)
        {
        	state.output.print("\n", log);
        	ind.printIndividual(state, log);
        }
*/        //f.printFitnessForHumans(state, log);
    }


	//@Override
	//public double[] getSemantic(EvolutionState state, GPNode node,
	//		int threadnum) 
	//{

		//return null;
	//}


	@Override
	public int getNumOfFitcases() {
		// TODO Auto-generated method stub
		return trainingOutputs.length;
	}


	@Override
	public double[] getOutputTraining() {
		return this.trainingOutputs;
	}


	@Override
	public int getNumOfTestcases() {
		return this.testingOutputs.length;
	}


	@Override
	public double[] getSemanticTesting(EvolutionState state, GPNode node,
			int threadnum) {
		RegressionData input = (RegressionData)(this.input);

		double[] testingSemantic = new double[testingInputs.length];
	
		for(int i = 0; i < testingInputs.length; i++)
		{
			currentValue = testingInputs[i];
            node.eval(state,threadnum,input,stack,null,this);
            testingSemantic[i] =  input.x;
		}
		
		return testingSemantic;
	}
        
    }
